[{"authors":null,"categories":null,"content":"Ruihao Gong is currently a associate research director and team leader of Model Toolchain Team at SenseTime Research under the supervision of Xiaogang Wang and Dahua Lin. He focuses on the system and algorithms for accelerating the industry model production, model deployment and model efficiency. His research interests include model quantization, model sparsity, hardware-friendly neural networks for various hardwares such as cloud servers and mobile/egde devices, building systems for large model training and inference, and various applications such as smart city and L2/L4 autonomous driving, personal AI assistants.\nNews:\n[2024.02] Our TFMQ-DM on Diffusion Model Quantization is accepted by CVPR 2024.\n[2024.01] Our QLLM method for LLM quantization is accepted by ICLR 2024.\n[2023.12] One paper on lane detection quantization and one paper on post-training sparsity are accepted by AAAI 2024.\n[2023.11] We released EasyLLM: a training framework for Large Language Model and Vision Language Model.\n[2023.10] Our team won the championship of LPCV 2023.\n[2023.10] One paper Outlier Suppression+ for LLM quantization is accepted by EMNLP 2023.\n[2023.08] We released LightLLM: a serving framework for Large Language Model and Vision Language Model.\n[2023.07] One paper on model size compression is accepted by ICCV 2023.\n[2023.06] One FamilySeer paper on deep learning compiler is accepted by ICPP 2023.\n[2023.04] One SysNoise paper on model robustness is accepted by MLSys 2023. \n Download my resumé. -- ","date":1717200000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1709045436,"objectID":"dd1480a0826a21d038e33effc41a0f78","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Ruihao Gong is currently a associate research director and team leader of Model Toolchain Team at SenseTime Research under the supervision of Xiaogang Wang and Dahua Lin. He focuses on the system and algorithms for accelerating the industry model production, model deployment and model efficiency.","tags":null,"title":"Ruihao Gong","type":"authors"},{"authors":["Ruihao Gong","Yang Yong","Zining Wang","Jinyang Guo","Xiuying Wei","Yuqing Ma","Xianglong Liu"],"categories":[],"content":"","date":1717200000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1709045398,"objectID":"69e7d672e40d55be441ab8f1a1f740ab","permalink":"https://example.com/publication/2024-aaai-pts/","publishdate":"2024-02-27T14:49:58.707878Z","relpermalink":"/publication/2024-aaai-pts/","section":"publication","summary":"","tags":[],"title":"Fast and Controllable Post-training Sparsity: Learning Optimal Sparsity Allocation with Global Constraint in Minutes","type":"publication"},{"authors":["Yunqian Fan","Xiuying Wei","Ruihao Gong","Yuqing Ma","Xiangguo Zhang","Qi Zhang","Xianglong Liu"],"categories":[],"content":"","date":1717200000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1709045435,"objectID":"719ef878d425762e12db139d27b44211","permalink":"https://example.com/publication/2024-aaai-lanequant/","publishdate":"2024-02-27T14:50:35.78542Z","relpermalink":"/publication/2024-aaai-lanequant/","section":"publication","summary":"","tags":[],"title":"Selective Focus: Investigating Semantics Sensitivity in Post-training Quantization for Lane Detection","type":"publication"},{"authors":["Yushi Huang","Ruihao Gong","Jing Liu","Tianlong Chen","Xianglong Liu"],"categories":[],"content":"","date":1717200000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1709045434,"objectID":"c6513f0cbd1de89504599f0ed27f3feb","permalink":"https://example.com/publication/2024-cvpr-tfmq-dm/","publishdate":"2024-02-27T14:50:34.775696Z","relpermalink":"/publication/2024-cvpr-tfmq-dm/","section":"publication","summary":"","tags":[],"title":"TFMQ-DM: Temporal Feature Maintenance Quantization for Diffusion Models","type":"publication"},{"authors":null,"categories":null,"content":"LightLLM is a Python-based LLM (Large Language Model) inference and serving framework, notable for its lightweight design, easy scalability, and high-speed performance. LightLLM harnesses the strengths of numerous well-regarded open-source implementations, including but not limited to FasterTransformer, TGI, vLLM, and FlashAttention.\nFeatures  Tri-process asynchronous collaboration: tokenization, model inference, and detokenization are performed asynchronously, leading to a considerable improvement in GPU utilization. Nopad (Unpad): offers support for nopad attention operations across multiple models to efficiently handle requests with large length disparities. Dynamic Batch: enables dynamic batch scheduling of requests FlashAttention: incorporates FlashAttention to improve speed and reduce GPU memory footprint during inference. Tensor Parallelism: utilizes tensor parallelism over multiple GPUs for faster inference. Token Attention: implements token-wise’s KV cache memory management mechanism, allowing for zero memory waste during inference. High-performance Router: collaborates with Token Attention to meticulously manage the GPU memory of each token, thereby optimizing system throughput. Int8KV Cache: This feature will increase the capacity of tokens to almost twice as much. only llama support.  Supported Model List  BLOOM LLaMA LLaMA V2 StarCoder Qwen-7b ChatGLM2-6b Baichuan-7b Baichuan2-7b Baichuan2-13b Baichuan-13b InternLM-7b Yi-34b Qwen-VL Qwen-VL-Chat Llava-7b Llava-13b Mixtral Stablelm MiniCPM  ","date":1706313600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706313600,"objectID":"336f0fa62b8d6d285a893e331f6dce52","permalink":"https://example.com/project/lightllm/","publishdate":"2024-01-27T00:00:00Z","relpermalink":"/project/lightllm/","section":"project","summary":"A Python-based LLM inference and serving framework, notable for its lightweight design, easy scalability, and high-speed performance.","tags":["LLM"],"title":"LightLLM","type":"project"},{"authors":null,"categories":null,"content":"Built upon Megatron-Deepspeed and HuggingFace Trainer, EasyLLM has reorganized the code logic with a focus on usability. While enhancing usability, it also ensures training efficiency.\n","date":1706227200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706227200,"objectID":"5c3559e0e4f502766705aaae34808264","permalink":"https://example.com/project/easyllm/","publishdate":"2024-01-26T00:00:00Z","relpermalink":"/project/easyllm/","section":"project","summary":"Built upon Megatron-Deepspeed and HuggingFace Trainer, EasyLLM has reorganized the code logic with a focus on usability. While enhancing usability, it also ensures training efficiency.","tags":["LLM"],"title":"EasyLLM","type":"project"},{"authors":["Jing Liu","Ruihao Gong","Xiuying Wei","Zhiwei Dong","Jianfei Cai","Bohan Zhuang"],"categories":[],"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1709045391,"objectID":"8af2b207765629152e2472da951a8d90","permalink":"https://example.com/publication/2024-iclr-qllm/","publishdate":"2024-02-27T14:49:51.437431Z","relpermalink":"/publication/2024-iclr-qllm/","section":"publication","summary":"","tags":[],"title":"QLLM: Accurate and Efficient Low-Bitwidth Quantization for Large Language Models","type":"publication"},{"authors":["Bo Li","Yongqiang Yao","Jingru Tan","Ruihao Gong","Jianwei Lu","Ye Luo"],"categories":[],"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1709045399,"objectID":"cb38eafecffcef26d0921a8e047e0711","permalink":"https://example.com/publication/2023-nn-rect/","publishdate":"2024-02-27T14:49:59.256625Z","relpermalink":"/publication/2023-nn-rect/","section":"publication","summary":"Natural data typically exhibits a long-tailed distribution, presenting great challenges for recognition tasks. Due to the extreme scarcity of training instances, tail classes often show inferior performance. In this paper, we investigate the problem within the trendy visual-language (VL) framework and find that the performance bottleneck mainly arises from the recognition confusion between tail classes and their highly correlated head classes. Building upon this observation, unlike previous research primarily emphasizing class frequency in addressing long-tailed issues, we take a novel perspective by incorporating a crucial additional factor namely class correlation. Specifically, we model the representation learning procedure for each sample as two parts, i.e., a special part that learns the unique properties of its own class and a common part that learns shared characteristics among classes. By analysis, we discover that the learning process of common representation is easily biased toward head classes. Because of the bias, the network may lean towards the biased common representation as classification criteria, rather than prioritizing the crucial information encapsulated within the specific representation, ultimately leading to recognition confusion. To solve the problem, based on the VL framework, we introduce the rectification contrastive term (ReCT) to rectify the representation bias, according to semantic hints and training status. Extensive experiments on three widely-used long-tailed datasets demonstrate the effectiveness of ReCT. On iNaturalist2018, it achieves an overall accuracy of 75.4%, surpassing the baseline by 3.6 points in a ResNet-50 visual backbone.","tags":["Long-tailed recognition","Vision-language model","Representation bias"],"title":"Rectify representation bias in vision-language models for long-tailed recognition","type":"publication"},{"authors":["Xiuying Wei","Yunchen Zhang","Yuhang Li","Xiangguo Zhang","Ruihao Gong","Jinyang Guo","Xianglong Liu"],"categories":[],"content":"","date":1701388800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1709045436,"objectID":"c7883fcf05f1818ad968ef1f648a23c3","permalink":"https://example.com/publication/2023-emnlp-osplus/","publishdate":"2024-02-27T14:50:36.439363Z","relpermalink":"/publication/2023-emnlp-osplus/","section":"publication","summary":"Post-training quantization (PTQ) of transformer language models faces significant challenges due to the existence of detrimental outliers in activations. We observe that these outliers are concentrated in specific channels and are asymmetric across channels. To address this issue, we propose the Outlier Suppression+ (OS+) framework, which contains the channel-wise shifting for asymmetry and channel-wise scaling for concentration. We show that these operations can be seamlessly migrated into subsequent modules while maintaining equivalence. Second, we propose a fast and stable scheme to calculate effective shifting and scaling values. The channel-wise shifting aligns the center of each channel for removal of outlier asymmetry. The channel-wise scaling quantitatively evaluates changes brought by migration and quantization for better quantization burden balance. We validate our OS+ under both standard and fine-grained quantization settings with models including BERT, OPT, BLOOM, BLOOMZ, and LLaMA. Comprehensive results across various tasks demonstrate the superiority of our approach. Especially, with standard quantization, OS+ can achieve near-floating-point performance on both small models and large language models on 8-bit and 6-bit. Besides, we establish a new state-of-the-art for 4-bit BERT with 15.5% improvement. Our code is available at r̆lhttps://github.com/ModelTC/Outlier_Suppression_Plus.","tags":[],"title":"Outlier Suppression+: Accurate quantization of large language models by equivalent and effective shifting and scaling","type":"publication"},{"authors":["Yumeng Shi","Shihao Bai","Xiuying Wei","Ruihao Gong","Jianlei Yang"],"categories":[],"content":"","date":1696118400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1709045392,"objectID":"3c4533babf9ba3deca4f9d0b60cc9e3f","permalink":"https://example.com/publication/2023-iccv-l-2-compress/","publishdate":"2024-02-27T14:49:52.450401Z","relpermalink":"/publication/2023-iccv-l-2-compress/","section":"publication","summary":"","tags":[],"title":"Lossy and Lossless (L2) Post-training Model Size Compression","type":"publication"},{"authors":null,"categories":null,"content":"This project contains the complete implementation that wins the LPCV 2023 Challenge.\nThe leaderboard can be seen at LPCV2023 Leaderboard (ModelTC Team).\nCode:\n https://github.com/ModelTC/LPCV_2023_solution https://github.com/ModelTC/UP_LPCV2023_Plugin.  ","date":1693094400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1693094400,"objectID":"200f02de25d789f7b75faac1aa20f3f5","permalink":"https://example.com/project/lpcv2023-fpga-track/","publishdate":"2023-08-27T00:00:00Z","relpermalink":"/project/lpcv2023-fpga-track/","section":"project","summary":"The implementaion of winner solution for LPCV 2023 Challenge","tags":["Deep Learning"],"title":"LPCV 2023 Winner Solution","type":"project"},{"authors":["Yuqing Ma","Hainan Li","Zhange Zhang","Jinyang Guo","Shanghang Zhang","Ruihao Gong","Xianglong Liu"],"categories":[],"content":"","date":1685577600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1709045391,"objectID":"13fc4bbe75a0bde7c9a3e3d333ed6be0","permalink":"https://example.com/publication/2023-cvpr-allow/","publishdate":"2024-02-27T14:49:50.881083Z","relpermalink":"/publication/2023-cvpr-allow/","section":"publication","summary":"","tags":[],"title":"Annealing-Based Label-Transfer Learning for Open World Object Detection","type":"publication"},{"authors":["Aishan Liu","Shiyu Tang","Siyuan Liang","Ruihao Gong","Boxi Wu","Xianglong Liu","Dacheng Tao"],"categories":[],"content":"","date":1685577600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1709045392,"objectID":"3b8e5951d9968076b9ee8648307dbc5d","permalink":"https://example.com/publication/2023-cvpr-robust-model/","publishdate":"2024-02-27T14:49:51.867714Z","relpermalink":"/publication/2023-cvpr-robust-model/","section":"publication","summary":"","tags":[],"title":"Exploring the Relationship Between Architectural Design and Adversarially Robust Generalization","type":"publication"},{"authors":["Yajun Gao","Shihao Bai","Xiaowei Zhao","Ruihao Gong","Yan Wu","Yuqing Ma"],"categories":[],"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1709045435,"objectID":"fcb38be1b1a0268d6618ef903b57508f","permalink":"https://example.com/publication/2023-electronics-semantic-diffusion/","publishdate":"2024-02-27T14:50:35.287005Z","relpermalink":"/publication/2023-electronics-semantic-diffusion/","section":"publication","summary":"Transfer learning could improve the robustness and generalization of the model, reducing potential privacy and security risks. It operates by fine-tuning a pre-trained model on downstream datasets. This process not only enhances the model’s capacity to acquire generalizable features but also ensures an effective alignment between upstream and downstream knowledge domains. Transfer learning can effectively speed up the model convergence when adapting to novel tasks, thereby leading to the efficient conservation of both data and computational resources. However, existing methods often neglect the discrepant downstream–upstream connections. Instead, they rigidly preserve the upstream information without an adequate regularization of the downstream semantic discrepancy. Consequently, this results in weak generalization, issues with collapsed classification, and an overall inferior performance. The main reason lies in the collapsed downstream–upstream connection due to the mismatched semantic granularity. Therefore, we propose a discrepant semantic diffusion method for transfer learning, which could adjust the mismatched semantic granularity and alleviate the collapsed classification problem to improve the transfer learning performance. Specifically, the proposed framework consists of a Prior-Guided Diffusion for pre-training and a discrepant diffusion for fine-tuning. Firstly, the Prior-Guided Diffusion aims to empower the pre-trained model with the semantic-diffusion ability. This is achieved through a semantic prior, which consequently provides a more robust pre-trained model for downstream classification. Secondly, the discrepant diffusion focuses on encouraging semantic diffusion. Its design intends to avoid the unwanted semantic centralization, which often causes the collapsed classification. Furthermore, it is constrained by the semantic discrepancy, serving to elevate the downstream discrimination capabilities. Extensive experiments on eight prevalent downstream classification datasets confirm that our method can outperform a number of state-of-the-art approaches, especially for fine-grained datasets or datasets dissimilar to upstream data (e.g., 3.75% improvement for Cars dataset and 1.79% improvement for SUN dataset under the few-shot setting with 15% data). Furthermore, the experiments of data sparsity caused by privacy protection successfully validate our proposed method’s effectiveness in the field of artificial intelligence security.","tags":[],"title":"Discrepant Semantic Diffusion Boosts Transfer Learning Robustness","type":"publication"},{"authors":["Mingzhen Li","Hailong Yang","Shanjun Zhang","Fengwei Yu","Ruihao Gong","Yi Liu","Zhongzhi Luan","Depei Qian"],"categories":[],"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1709045393,"objectID":"3960b9825805bbabd610e05717b0d166","permalink":"https://example.com/publication/2023-icpp-familyseer/","publishdate":"2024-02-27T14:49:53.045075Z","relpermalink":"/publication/2023-icpp-familyseer/","section":"publication","summary":"The requirement for deploying deep learning (DL) models efficiently has boosted the research of DL compilers. Especially, the difficulty of generating optimized tensor programs has driven DL compilers to commonly adopt the auto-tuning approaches. Consequently, there are increasing demands to improve the effectiveness of auto-tuning in terms of both search efficiency and search quality. However, existing auto-tuning approaches commonly treat subgraphs individually and overlook the similarities among them, and thus fail to generate better tensor programs under limited time budget. To address the above drawbacks, we propose FamilySeer, an auto-tuning framework that can generate better tensor programs by exploiting the subgraph similarities. Specifically, FamilySeer organizes similar subgraphs into subgraph families, where the cost models are built at family basis with improved accuracy for estimating high potential program candidates. To further leverage the similarity, FamilySeer uses the accurate cost model per family to reduce the number of program candidates for costly hardware measurements without degrading search quality. The experiment results on various DL models demonstrate that FamilySeer can achieve better search efficiency/quality on both CPU and GPU platforms compared to the state-of-the-art auto-tuning framework.","tags":["Auto-tuning","Performance Optimization","Subgraph Similarity","Tensor Compiler"],"title":"Exploiting Subgraph Similarities for Efficient Auto-tuning of Tensor Programs","type":"publication"},{"authors":["Yan Wang","Yuhang Li","Ruihao Gong","Aishan Liu","Jian Hu","Yongqiang Yao","Yunchen Zhang","Fengwei Yu","Xianglong Liu"],"categories":[],"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1709045390,"objectID":"336bb9653abd1624d7b11c0a4182caed","permalink":"https://example.com/publication/2023-mlsys-sysnoise/","publishdate":"2024-02-27T14:49:50.213014Z","relpermalink":"/publication/2023-mlsys-sysnoise/","section":"publication","summary":"","tags":[],"title":"SysNoise: Exploring and Benchmarking Training-Deployment System Inconsistency","type":"publication"},{"authors":["Haotong Qin","Xiangguo Zhang","Ruihao Gong","Yifu Ding","Yi Xu","Xianglong Liu"],"categories":[],"content":"","date":1664582400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1665313169,"objectID":"ab1602cd007b6665dd25355a48a92d41","permalink":"https://example.com/publication/2022-ijcv-bnn/","publishdate":"2022-10-09T10:59:29.424497Z","relpermalink":"/publication/2022-ijcv-bnn/","section":"publication","summary":"","tags":[],"title":"Distribution-Sensitive Information Retention for Accurate Binary Neural Network","type":"publication"},{"authors":["Xiuying Wei","Yunchen Zhang","Xiangguo Zhang","Ruihao Gong","Shanghang Zhang","Qi Zhang","Fengwei Yu","Xianglong Liu"],"categories":[],"content":"","date":1664236800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1665307412,"objectID":"18c0861f77fda2cc73452e3cb48c1ed7","permalink":"https://example.com/publication/2022-neurips-outlier-suppression/","publishdate":"2022-10-09T09:23:32.392172Z","relpermalink":"/publication/2022-neurips-outlier-suppression/","section":"publication","summary":"","tags":[],"title":"Outlier Suppression: Pushing the Limit of Low-bit Transformer Language Models","type":"publication"},{"authors":[],"categories":null,"content":"","date":1653111000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1653111000,"objectID":"98c3cfb23d0ac319ed769db45fd343ab","permalink":"https://example.com/talk/when-industrial-model-toolchain-meets-xilinx-fpga/","publishdate":"2022-05-21T00:00:00Z","relpermalink":"/talk/when-industrial-model-toolchain-meets-xilinx-fpga/","section":"event","summary":"introduce the winner solution of LPCV 2021 FPGA track.","tags":[],"title":"When industrial model toolchain meets Xilinx FPGA","type":"event"},{"authors":["Yuxuan Wang","Jiakai Wang","Zixin Yin","Ruihao Gong","Jingyi Wang","Aishan Liu","Xianglong Liu"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1709043579,"objectID":"c70804735d636fd6e5dcb94b49de219d","permalink":"https://example.com/publication/2022-mm-adv-vit/","publishdate":"2024-02-27T14:19:39.33256Z","relpermalink":"/publication/2022-mm-adv-vit/","section":"publication","summary":"Vision transformers (ViTs) are prevailing among several visual recognition tasks, therefore drawing intensive interest in generating adversarial examples against them. Different from CNNs, ViTs enjoy unique architectures, e.g., self-attention and image-embedding, which are commonly-shared features among various types of transformer-based models. However, existing adversarial methods suffer from weak transferable attacking ability due to the overlook of these architectural features. To address the problem, we propose an Architecture-oriented Transferable Attacking (ATA) framework to generate transferable adversarial examples by activating the uncertain attention and perturbing the sensitive embedding.Specifically, we first locate the patch-wise attentional regions that mostly affect model perception, therefore intensively activating the uncertainty of the attention mechanism and confusing the model decisions in turn.Furthermore, we search the pixel-wise attacking positions that are more likely to derange the embedded tokens using sensitive embedding perturbation, which could serve as a strong transferable attacking pattern.By jointly confusing the unique yet widely-used architectural features among transformer-based models, we can activate strong attacking transferability among diverse ViTs. Extensive experiments on large-scale dataset ImageNet using various popular transformers demonstrate that our ATA outperforms other baselines by large margins (at least +15% Attack Success Rate). Our code is available at https://github.com/nlsde-safety-team/ATA","tags":["vision transformer","transferability","adversarial attacks"],"title":"Generating Transferable Adversarial Examples against Vision Transformers","type":"publication"},{"authors":["Liang Liu","Mingzhu Shen","Ruihao Gong","Fengwei Yu","Hailong Yang"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657038936,"objectID":"37c12c6dff396e765c8bb55eeaf777dd","permalink":"https://example.com/publication/2022-icpp-nnlqp/","publishdate":"2022-07-05T16:35:36.019791Z","relpermalink":"/publication/2022-icpp-nnlqp/","section":"publication","summary":"","tags":["neural network","multi-platform","latency query","latency prediction"],"title":"NNLQP: A Multi-Platform Neural Network Latency Query and Prediction System with An Evolving Database","type":"publication"},{"authors":["Xiuying Wei","Ruihao Gong","Yuhang Li","Xianglong Liu","Fengwei Yu"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648369342,"objectID":"3515857ad8bec5c61243a1f7a0facdc3","permalink":"https://example.com/publication/2022-iclr-qdrop/","publishdate":"2022-03-27T08:22:22.654761Z","relpermalink":"/publication/2022-iclr-qdrop/","section":"publication","summary":"","tags":[],"title":"QDrop: Randomly Dropping Quantization for Extremely Low-bit Post-Training Quantization","type":"publication"},{"authors":["Yuhang Li","Feng Zhu","Ruihao Gong","Mingzhu Shen","Xin Dong","Fengwei Yu","Shaoqing Lu","Shi Gu"],"categories":[],"content":"","date":1633046400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654758959,"objectID":"4441275e1fe57d1e622ba3cf1752c1b5","permalink":"https://example.com/publication/2021-iccv-mixmix/","publishdate":"2022-06-09T07:15:59.63863Z","relpermalink":"/publication/2021-iccv-mixmix/","section":"publication","summary":"","tags":[],"title":"MixMix: All You Need for Data-Free Compression Are Feature and Data Mixing","type":"publication"},{"authors":["Mingzhu Shen","Feng Liang","Ruihao Gong","Yuhang Li","Chuming Li","Chen Lin","Fengwei Yu","Junjie Yan","Wanli Ouyang"],"categories":[],"content":"","date":1633046400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654756516,"objectID":"bc2e6e8de478408f5140b43a1652bbc3","permalink":"https://example.com/publication/2021-iccv-oqa/","publishdate":"2022-06-09T06:34:53.78988Z","relpermalink":"/publication/2021-iccv-oqa/","section":"publication","summary":"","tags":[],"title":"Once Quantization-Aware Training: High Performance Extremely Low-Bit Architecture Search","type":"publication"},{"authors":[],"categories":null,"content":"A summary can be seen at Link.\n","date":1630090800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630090800,"objectID":"f7c436c4bf77b772d25113e40f45828b","permalink":"https://example.com/talk/research-on-post-training-quantization-from-classic-to-original/","publishdate":"2021-08-27T00:00:00Z","relpermalink":"/talk/research-on-post-training-quantization-from-classic-to-original/","section":"event","summary":"Our research journal on PTQ for a better industry application.","tags":[],"title":"Research on Post-training Quantization - From classic to original","type":"event"},{"authors":null,"categories":null,"content":"This project contains the complete implementation that wins the LPCV 2021 FPGA track, which can run an object detection model with an extremely high efficiency and accuracy.\nThe leaderboard can be seen at LPCV2021 Leaderboard (Spring Team).\n","date":1630022400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630022400,"objectID":"4c4f90bd2047d38d22bbc2376fc38051","permalink":"https://example.com/project/lpcv2021-fpga-track/","publishdate":"2021-08-27T00:00:00Z","relpermalink":"/project/lpcv2021-fpga-track/","section":"project","summary":"The implementaion of winner solution for LPCV 2021 FPGA track","tags":["Deep Learning"],"title":"LPCV 2021 Winner Solution of FPGA Track","type":"project"},{"authors":["Ruihao Gong"],"categories":["Deep learning compiler","Sparsity"],"content":"For details, please refer to Link.\n","date":1629936000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629936000,"objectID":"ba8d27cf66c13e30779619ef8bc2a7d5","permalink":"https://example.com/post/2021-tvm-sparsity/","publishdate":"2021-08-26T00:00:00Z","relpermalink":"/post/2021-tvm-sparsity/","section":"post","summary":"Realize efficient sparsity with 50% sparsity by TVM.","tags":["Sparsity","TVM"],"title":"Block Sparsity on TVM -- 50% spasity = 1.6 speed up + \u003c 1% accuracy loss","type":"post"},{"authors":["Ruihao Gong"],"categories":["Quantization","Framework"],"content":"For details, please refer to Link.\n","date":1629158400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629158400,"objectID":"f5a21c2ca7142c3406f60a5f58759a61","permalink":"https://example.com/post/2021-quant-tool/","publishdate":"2021-08-17T00:00:00Z","relpermalink":"/post/2021-quant-tool/","section":"post","summary":"Introduce some quantization frameworks from hardware vendors or universities.","tags":["Quantization"],"title":"Quantization frameworks","type":"post"},{"authors":null,"categories":null,"content":"MQBench is an open-source model quantization toolkit based on PyTorch fx.\nThe envision of MQBench is to provide:\n SOTA Algorithms. With MQBench, the hardware vendors and researchers can benefit from the latest research progress in academia. Powerful Toolkits. With the toolkit, quantization node can be inserted to the original PyTorch module automatically with respect to the specific hardware. After training, the quantized model can be smoothly converted to the format that can inference on the real device.  The documentation can be seen at Documentation and the website is at Link.\n","date":1627344000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627344000,"objectID":"fe1a5b080e05f4456bd0c49e563c4c9f","permalink":"https://example.com/project/mqbench/","publishdate":"2021-07-27T00:00:00Z","relpermalink":"/project/mqbench/","section":"project","summary":"MQBench is an open-source model quantization toolkit based on PyTorch fx, which provides **SOTA Algorithms** and **Powerful Toolkits**.","tags":["Deep Learning"],"title":"MQBench","type":"project"},{"authors":["Yuhang Li","Mingzhu Shen","Jian Ma","Yan Ren","Mingxin Zhao","Qi Zhang","Ruihao Gong","Fengwei Yu","Junjie Yan"],"categories":[],"content":"","date":1625097600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648369334,"objectID":"8bf3720e1e2a1e21675a4f06a182fb6d","permalink":"https://example.com/publication/2021-neuips-mqbench/","publishdate":"2022-03-27T08:22:14.729101Z","relpermalink":"/publication/2021-neuips-mqbench/","section":"publication","summary":"","tags":[],"title":"MQBench: Towards Reproducible and Deployable Model Quantization Benchmark","type":"publication"},{"authors":null,"categories":null,"content":"RobustART is a comprehensive Robustness investigation benchmark on ImageNet regarding ARchitectural design (49 human-designed off-the-shelf architectures and neural architecture searched networks) and Training techniques (10+ general ones e.g., extra training data, etc) towards diverse noises (adversarial, natural, and system noises).\nThe benchmark (including open-source toolkit, pre-trained model zoo, datasets, and analyses):\n presents an open-source platform for conducting comprehensive evaluation on diverse robustness types; provides a variety of pre-trained models with different training techniques to facilitate robustness evaluation; proposes a new view to better understand the mechanism towards designing robust DNN architectures, backed up by the analysis.  For more details, please refer to the website. We will continuously contribute to building this ecosystem for the community.\n","date":1624752000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624752000,"objectID":"3dd9814f55d90c7117890dfb89abfe54","permalink":"https://example.com/project/robustart/","publishdate":"2021-06-27T00:00:00Z","relpermalink":"/project/robustart/","section":"project","summary":"RobustART is a comprehensive Robustness investigation benchmark on ImageNet regarding ARchitectural design and Training techniques.","tags":["Deep Learning"],"title":"RobustART","type":"project"},{"authors":["Xiangguo Zhang","Haotong Qin","Yifu Ding","Ruihao Gong","Qinghua Yan","Renshuai Tao","Yuhang Li","Fengwei Yu","Xianglong Liu"],"categories":[],"content":"","date":1622505600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648366064,"objectID":"7603f1b906e99980ef3c1d514213e767","permalink":"https://example.com/publication/2021-cvpr-dsg/","publishdate":"2022-03-27T07:29:01.151846Z","relpermalink":"/publication/2021-cvpr-dsg/","section":"publication","summary":"","tags":[],"title":"Diversifying Sample Generation for Accurate Data-Free Quantization","type":"publication"},{"authors":[],"categories":null,"content":"","date":1620327600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620327600,"objectID":"853f96f86b48b0bf7142c165300af0e8","permalink":"https://example.com/talk/neural-network-model-compression/","publishdate":"2021-05-06T00:00:00Z","relpermalink":"/talk/neural-network-model-compression/","section":"event","summary":"A course about neural network compression for undergraduates and graduates of Tsinghua University.","tags":[],"title":"Neural Network Model Compression","type":"event"},{"authors":["Ruihao Gong"],"categories":["Deep learning compiler","Quantization","Transformer"],"content":"For details, please refer to Link.\n","date":1618790400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618790400,"objectID":"3a1bd9f77a5faf31d5e4b793cbef8317","permalink":"https://example.com/post/2021-vit-tvm-quant/","publishdate":"2021-04-19T00:00:00Z","relpermalink":"/post/2021-vit-tvm-quant/","section":"post","summary":"The first to support Int8 ViT for TVM, achieving a significant speed up.","tags":["Transformer","Quantization"],"title":"Int8 ViT on TVM, 1.5 speed up compared with TensorRT","type":"post"},{"authors":[],"categories":null,"content":"A summary can be seen at Link.\n","date":1618426800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618426800,"objectID":"5bcd7575cd4c816404d85f66bcdf08be","permalink":"https://example.com/talk/an-introduction-to-block-reconstruction-quantization/","publishdate":"2021-04-14T00:00:00Z","relpermalink":"/talk/an-introduction-to-block-reconstruction-quantization/","section":"event","summary":"An introduction to a SOTA PTQ algorithm - BRECQ.","tags":[],"title":"An Introduction to Block Reconstruction Quantization","type":"event"},{"authors":["Ruihao Gong"],"categories":["Quantization"],"content":"For details, please refer to Link.\n","date":1612742400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612742400,"objectID":"04a5137a00e40e6ac6826e565ef89410","permalink":"https://example.com/post/2021-quant-gap/","publishdate":"2021-02-08T00:00:00Z","relpermalink":"/post/2021-quant-gap/","section":"post","summary":"Analyze the gap between the academia and instustry.","tags":["Quantization"],"title":"Gap bettween the academia and industry, from the quantiztion perspective","type":"post"},{"authors":["Yuhang Li","Ruihao Gong","Xu Tan","Yang Yang","Peng Hu","Qi Zhang","Fengwei Yu","Wei Wang","Shi Gu"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648366065,"objectID":"107942126dbe50a9ab43652f0eccd489","permalink":"https://example.com/publication/2021-iclr-brecq/","publishdate":"2022-03-27T07:29:01.723129Z","relpermalink":"/publication/2021-iclr-brecq/","section":"publication","summary":"","tags":[],"title":"BRECQ: Pushing the Limit of Post-Training Quantization by Block Reconstruction","type":"publication"},{"authors":["Shiyu Tang","Ruihao Gong","Yan Wang","Aishan Liu","Jiakai Wang","Xinyun Chen","Fengwei Yu","Xianglong Liu","Dawn Song","Alan Yuille","Philip H. S. Torr","Dacheng Tao"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648369338,"objectID":"b6a3e2e944c7b43fff70bb715f7c1187","permalink":"https://example.com/publication/2021-arxiv-robustart/","publishdate":"2022-03-27T08:22:18.567278Z","relpermalink":"/publication/2021-arxiv-robustart/","section":"publication","summary":"","tags":[],"title":"RobustART: Benchmarking Robustness on Architecture Design and Training Techniques","type":"publication"},{"authors":[],"categories":null,"content":"A summary can be seen at Link\n","date":1591729200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591729200,"objectID":"dbfd7701d8642bf2d375412f65ad088e","permalink":"https://example.com/talk/an-introduction-to-quantization/","publishdate":"2020-06-09T00:00:00Z","relpermalink":"/talk/an-introduction-to-quantization/","section":"event","summary":"An introduction to the basics of model quantization and the relavant effective algorithms.","tags":[],"title":"An Introduction to Quantization","type":"event"},{"authors":["Haotong Qin","Ruihao Gong","Xianglong Liu","Mingzhu Shen","Ziran Wei","Fengwei Yu","Jingkuan Song"],"categories":[],"content":"","date":1590969600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648366067,"objectID":"b9430da794dbd1743eccf5e9deb72237","permalink":"https://example.com/publication/2020-cvpr-irnet/","publishdate":"2022-03-27T07:29:03.373611Z","relpermalink":"/publication/2020-cvpr-irnet/","section":"publication","summary":"","tags":[],"title":"Forward and Backward Information Retention for Accurate Binary Neural Networks","type":"publication"},{"authors":["Yudong Wu","Yichao Wu","Ruihao Gong","Yuanhao Lv","Ken Chen","Ding Liang","Xiaolin Hu","Xianglong Liu","Junjie Yan"],"categories":[],"content":"","date":1590969600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648366067,"objectID":"4f56f2df3811eb5cfff12a63bac70e85","permalink":"https://example.com/publication/2020-cvpr-rcmloss/","publishdate":"2022-03-27T07:29:03.922862Z","relpermalink":"/publication/2020-cvpr-rcmloss/","section":"publication","summary":"","tags":[],"title":"Rotation Consistent Margin Loss for Efficient Low-bit Face Recognition","type":"publication"},{"authors":["Feng Zhu","Ruihao Gong","Fengwei Yu","Xianglong Liu","Yanfei Wang","Zhelong Li","Xiuqi Yang","Junjie Yan"],"categories":[],"content":"","date":1590969600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648366068,"objectID":"ad1126ec12d50f3ae21276375e7b9b69","permalink":"https://example.com/publication/2020-cvpr-int-8-training/","publishdate":"2022-03-27T07:29:04.472601Z","relpermalink":"/publication/2020-cvpr-int-8-training/","section":"publication","summary":"","tags":[],"title":"Towards Unified INT8 Training for Convolutional Neural Network","type":"publication"},{"authors":["Mingzhu Shen","Xianglong Liu","Ruihao Gong","Kai Han"],"categories":[],"content":"","date":1588291200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648366065,"objectID":"0aebb1b84ac5e9a160c6f974f10a1c5e","permalink":"https://example.com/publication/2020-icassp-bbg/","publishdate":"2022-03-27T07:29:02.282811Z","relpermalink":"/publication/2020-icassp-bbg/","section":"publication","summary":"","tags":[],"title":"Balanced Binary Neural Networks with Gated Residual","type":"publication"},{"authors":["Yuhang Li","Ruihao Gong","Fengwei Yu","Xin Dong","Xianglong Liu"],"categories":[],"content":"","date":1585699200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648366066,"objectID":"4dbd646e758b7ce6813e79376e788921","permalink":"https://example.com/publication/2020-iclrw-dms/","publishdate":"2022-03-27T07:29:02.826575Z","relpermalink":"/publication/2020-iclrw-dms/","section":"publication","summary":"","tags":[],"title":"DMS: Differentiable Dimension Search for Binary Neural Networks","type":"publication"},{"authors":["Haotong Qin","Ruihao Gong","Xianglong Liu","Xiao Bai","Jingkuan Song","Nicu Sebe"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648366068,"objectID":"212f185d09ce3c066ebedcc2e396d21a","permalink":"https://example.com/publication/2020-pr-bnnsurvey/","publishdate":"2022-03-27T07:29:05.018687Z","relpermalink":"/publication/2020-pr-bnnsurvey/","section":"publication","summary":"The binary neural network, largely saving the storage and computation, serves as a promising technique for deploying deep models on resource-limited devices. However, the binarization inevitably causes severe information loss, and even worse, its discontinuity brings difficulty to the optimization of the deep network. To address these issues, a variety of algorithms have been proposed, and achieved satisfying progress in recent years. In this paper, we present a comprehensive survey of these algorithms, mainly categorized into the native solutions directly conducting binarization, and the optimized ones using techniques like minimizing the quantization error, improving the network loss function, and reducing the gradient error. We also investigate other practical aspects of binary neural networks such as the hardware-friendly design and the training tricks. Then, we give the evaluation and discussions on different tasks, including image classification, object detection and semantic segmentation. Finally, the challenges that may be faced in future research are prospected.","tags":["Binary neural network","Deep learning","Model compression","Network quantization","Model acceleration"],"title":"Binary neural networks: A survey","type":"publication"},{"authors":["Yuhang Li","Wei Wang","Haoli Bai","Ruihao Gong","Xin Dong","Fengwei Yu"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648366062,"objectID":"32738930d483fa6f4e26a6a2115188b4","permalink":"https://example.com/publication/2020-arxiv-ebs/","publishdate":"2022-03-27T07:28:59.476187Z","relpermalink":"/publication/2020-arxiv-ebs/","section":"publication","summary":"","tags":[],"title":"Efficient Bitwidth Search for Practical Mixed Precision Neural Network","type":"publication"},{"authors":["Qingchang Han","Yongmin Hu","Fengwei Yu","Hailong Yang","Bing Liu","Peng Hu","Ruihao Gong","Yanfei Wang","Rui Wang","Zhongzhi Luan","Depei Qian"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648366064,"objectID":"5b58a06350e087633976687b4a9bdca9","permalink":"https://example.com/publication/2020-icpp-lowbit/","publishdate":"2022-03-27T07:29:00.583344Z","relpermalink":"/publication/2020-icpp-lowbit/","section":"publication","summary":"With the continuous demand for higher accuracy of deep neural networks, the model size has increased significantly. Quantization is one of the most widely used model compression methods, which can effectively reduce the model size without severe accuracy loss. Modern processors such as ARM CPU and NVIDIA GPU have already provided the support of low-bit arithmetic instructions. However, there lack efficient and practical optimizations for convolution computation towards extremely low-bit on ARM CPU (e.g., 2 ∼ 8-bit) and NVIDIA GPU (e.g., 4-bit and 8-bit). This paper explores the performance optimization methods of extremely low-bit convolution on diverse architectures. On ARM CPU, we propose two instruction schemes for 2 ∼ 3-bit and 4 ∼ 8-bit convolution with corresponding register allocation methods. In addition, we re-design the GEMM computation with data padding and packing optimizations. We also implement winograd algorithm for convolution with some specific bit width (e.g., 4 ∼ 6-bit) to achieve higher performance. On NVIDIA GPU, we propose a data partition mechanism and multi-level memory access optimizations, to better adapt the computation to GPU thread and memory hierarchy. We also propose quantization fusion to eliminate unnecessary data access. The experiment results demonstrate our implementations achieve better performance of extremely low-bit convolution compared to the state-of-the-art frameworks and libraries such as ncnn and cuDNN. To the best of our knowledge, this is the first work that provides efficient implementations of extremely low-bit convolutions covering 2 ∼ 8-bit on ARM CPU and 4-bit/8-bit on NVIDIA GPU. ","tags":["NVIDIA GPU","Quantized Neural Network","Extremely Low-bit Convolution","Computation Optimization","ARM CPU"],"title":"Extremely Low-Bit Convolution Optimization for Quantized Neural Network on Modern Computer Architectures","type":"publication"},{"authors":["Ruihao Gong","Xianglong Liu","Shenghu Jiang","Tianxiang Li","Peng Hu","Jiazhen Lin","Fengwei Yu","Junjie Yan"],"categories":[],"content":"","date":1569888000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648366063,"objectID":"b2b8d8079ac76ff65a1d3a5926745606","permalink":"https://example.com/publication/2019-iccv-dsq/","publishdate":"2022-03-27T07:29:00.032371Z","relpermalink":"/publication/2019-iccv-dsq/","section":"publication","summary":"","tags":[],"title":"Differentiable Soft Quantization: Bridging Full-Precision and Low-Bit Neural Networks","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34;\rif porridge == \u0026#34;blueberry\u0026#34;:\rprint(\u0026#34;Eating...\u0026#34;)\r  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}}\r{{% fragment %}} **Two** {{% /fragment %}}\r{{% fragment %}} Three {{% /fragment %}}\r Press Space to play!\nOne \rTwo \rThree \r A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}}\r- Only the speaker can read these notes\r- Press `S` key to view\r{{% /speaker_note %}}\r Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}}\r{{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}}\r{{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}}\r  Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1,\r.reveal section h2,\r.reveal section h3 {\rcolor: navy;\r}\r  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://example.com/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Nelson Bighetti","Robert Ford"],"categories":[],"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1709045394,"objectID":"554c79a24fab6be5e0f3ac7872af293e","permalink":"https://example.com/publication/example-1/","publishdate":"2024-02-27T14:49:54.819555Z","relpermalink":"/publication/example-1/","section":"publication","summary":"","tags":[],"title":"An example conference paper","type":"publication"}]