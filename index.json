[{"authors":null,"categories":null,"content":"Ruihao Gong is currently a senior researcher at SenseTime. Before this, he studied at Beihang University under the supervision of Prof. Xianglong Liu. Since 2017, he worked on the build-up of computer vision systems and model quantization as an intern at Sensetime Research, where he enjoyed working with the talented researchers and grew up a lot with the help of Fengwei Yu, Wei Wu, Jing Shao, and Junjie Yan. During the early time of the internship, he independently took responsibility for the development of intelligent video analysis system Sensevideo. Later, he started the research on model quantization which can speed up the inference and even the training of neural networks on edge devices. Now he is devoted to further promoting the accuracy of extremely low-bit models and the auto-deployment of quantized models.\n Download my resum√©. --\r","date":1640995200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1648369342,"objectID":"dd1480a0826a21d038e33effc41a0f78","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Ruihao Gong is currently a senior researcher at SenseTime. Before this, he studied at Beihang University under the supervision of Prof. Xianglong Liu. Since 2017, he worked on the build-up of computer vision systems and model quantization as an intern at Sensetime Research, where he enjoyed working with the talented researchers and grew up a lot with the help of Fengwei Yu, Wei Wu, Jing Shao, and Junjie Yan.","tags":null,"title":"Ruihao Gong","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Wowchemy‚Äôs Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://example.com/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Xiuying Wei","Ruihao Gong","Yuhang Li","Xianglong Liu","Fengwei Yu"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648369342,"objectID":"3515857ad8bec5c61243a1f7a0facdc3","permalink":"https://example.com/publication/2022-iclr-qdrop/","publishdate":"2022-03-27T08:22:22.654761Z","relpermalink":"/publication/2022-iclr-qdrop/","section":"publication","summary":"","tags":[],"title":"QDrop: Randomly Dropping Quantization for Extremely Low-bit Post-Training Quantization","type":"publication"},{"authors":null,"categories":null,"content":"This project contains the complete implementation that wins the LPCV 2021 FPGA track, which can run an object detection model with an extremely high efficiency and accuracy.\nThe leaderboard can be seen at LPCV2021 Leaderboard (Spring Team).\n","date":1630022400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630022400,"objectID":"4c4f90bd2047d38d22bbc2376fc38051","permalink":"https://example.com/project/lpcv2021-fpga-track/","publishdate":"2021-08-27T00:00:00Z","relpermalink":"/project/lpcv2021-fpga-track/","section":"project","summary":"The implementaion of winner solution for LPCV 2021 FPGA track","tags":["Deep Learning"],"title":"LPCV2021 Winner Solution of FPGA Track","type":"project"},{"authors":null,"categories":null,"content":"MQBench is an open-source model quantization toolkit based on PyTorch fx.\nThe envision of MQBench is to provide:\n SOTA Algorithms. With MQBench, the hardware vendors and researchers can benefit from the latest research progress in academia. Powerful Toolkits. With the toolkit, quantization node can be inserted to the original PyTorch module automatically with respect to the specific hardware. After training, the quantized model can be smoothly converted to the format that can inference on the real device.  The documentation can be seen at Documentation and the website is at Link.\n","date":1627344000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627344000,"objectID":"fe1a5b080e05f4456bd0c49e563c4c9f","permalink":"https://example.com/project/mqbench/","publishdate":"2021-07-27T00:00:00Z","relpermalink":"/project/mqbench/","section":"project","summary":"MQBench is an open-source model quantization toolkit based on PyTorch fx, which provides **SOTA Algorithms** and **Powerful Toolkits**.","tags":["Deep Learning"],"title":"MQBench","type":"project"},{"authors":["Yuhang Li","Mingzhu Shen","Jian Ma","Yan Ren","Mingxin Zhao","Qi Zhang","Ruihao Gong","Fengwei Yu","Junjie Yan"],"categories":[],"content":"","date":1625097600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648369334,"objectID":"8bf3720e1e2a1e21675a4f06a182fb6d","permalink":"https://example.com/publication/2021-neuips-mqbench/","publishdate":"2022-03-27T08:22:14.729101Z","relpermalink":"/publication/2021-neuips-mqbench/","section":"publication","summary":"","tags":[],"title":"MQBench: Towards Reproducible and Deployable Model Quantization Benchmark","type":"publication"},{"authors":null,"categories":null,"content":"RobustART is a comprehensive Robustness investigation benchmark on ImageNet regarding ARchitectural design (49 human-designed off-the-shelf architectures and neural architecture searched networks) and Training techniques (10+ general ones e.g., extra training data, etc) towards diverse noises (adversarial, natural, and system noises).\nThe benchmark (including open-source toolkit, pre-trained model zoo, datasets, and analyses):\n presents an open-source platform for conducting comprehensive evaluation on diverse robustness types; provides a variety of pre-trained models with different training techniques to facilitate robustness evaluation; proposes a new view to better understand the mechanism towards designing robust DNN architectures, backed up by the analysis.  For more details, please refer to the website. We will continuously contribute to building this ecosystem for the community.\n","date":1624752000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624752000,"objectID":"3dd9814f55d90c7117890dfb89abfe54","permalink":"https://example.com/project/robustart/","publishdate":"2021-06-27T00:00:00Z","relpermalink":"/project/robustart/","section":"project","summary":"RobustART is a comprehensive Robustness investigation benchmark on ImageNet regarding ARchitectural design and Training techniques.","tags":["Deep Learning"],"title":"RobustART","type":"project"},{"authors":["Xiangguo Zhang","Haotong Qin","Yifu Ding","Ruihao Gong","Qinghua Yan","Renshuai Tao","Yuhang Li","Fengwei Yu","Xianglong Liu"],"categories":[],"content":"","date":1622505600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648366064,"objectID":"7603f1b906e99980ef3c1d514213e767","permalink":"https://example.com/publication/2021-cvpr-dsg/","publishdate":"2022-03-27T07:29:01.151846Z","relpermalink":"/publication/2021-cvpr-dsg/","section":"publication","summary":"","tags":[],"title":"Diversifying Sample Generation for Accurate Data-Free Quantization","type":"publication"},{"authors":["Yuhang Li","Ruihao Gong","Xu Tan","Yang Yang","Peng Hu","Qi Zhang","Fengwei Yu","Wei Wang","Shi Gu"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648366065,"objectID":"107942126dbe50a9ab43652f0eccd489","permalink":"https://example.com/publication/2021-iclr-brecq/","publishdate":"2022-03-27T07:29:01.723129Z","relpermalink":"/publication/2021-iclr-brecq/","section":"publication","summary":"","tags":[],"title":"BRECQ: Pushing the Limit of Post-Training Quantization by Block Reconstruction","type":"publication"},{"authors":["Shiyu Tang","Ruihao Gong","Yan Wang","Aishan Liu","Jiakai Wang","Xinyun Chen","Fengwei Yu","Xianglong Liu","Dawn Song","Alan Yuille","Philip H. S. Torr","Dacheng Tao"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648369338,"objectID":"b6a3e2e944c7b43fff70bb715f7c1187","permalink":"https://example.com/publication/2021-arxiv-robustart/","publishdate":"2022-03-27T08:22:18.567278Z","relpermalink":"/publication/2021-arxiv-robustart/","section":"publication","summary":"","tags":[],"title":"RobustART: Benchmarking Robustness on Architecture Design and Training Techniques","type":"publication"},{"authors":["Ruihao Gong","Âê≥ÊÅ©ÈÅî"],"categories":["Demo","ÊïôÁ®ã"],"content":"Overview  The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site The template can be modified and customised to suit your needs. It‚Äôs a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a no-code solution (write in Markdown and customize with YAML parameters) and having flexibility to later add even deeper personalization with HTML and CSS You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more    The template is mobile first with a responsive design to ensure that your site looks stunning on every device.  Get Started  üëâ Create a new site üìö Personalize your site üí¨ Chat with the Wowchemy community or Hugo community üê¶ Twitter: @wowchemy @GeorgeCushen #MadeWithWowchemy üí° Request a feature or report a bug for Wowchemy ‚¨ÜÔ∏è Updating Wowchemy? View the Update Tutorial and Release Notes  Crowd-funded open-source software To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.\n‚ù§Ô∏è Click here to become a sponsor and help support Wowchemy‚Äôs future ‚ù§Ô∏è As a token of appreciation for sponsoring, you can unlock these awesome rewards and extra features ü¶Ñ‚ú®\nEcosystem  Hugo Academic CLI: Automatically import publications from BibTeX  Inspiration Check out the latest demo of what you‚Äôll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\nFeatures  Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 34+ language packs including English, ‰∏≠Êñá, and Portugu√™s Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files.  Themes Wowchemy and its templates come with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://example.com/post/getting-started/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Welcome üëã We know that first impressions are important, so we've populated your new site with some initial content to help you get familiar with everything in no time.","tags":["Academic","ÂºÄÊ∫ê"],"title":"Welcome to Wowchemy, the website builder for Hugo","type":"post"},{"authors":["Haotong Qin","Ruihao Gong","Xianglong Liu","Mingzhu Shen","Ziran Wei","Fengwei Yu","Jingkuan Song"],"categories":[],"content":"","date":1590969600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648366067,"objectID":"b9430da794dbd1743eccf5e9deb72237","permalink":"https://example.com/publication/2020-cvpr-irnet/","publishdate":"2022-03-27T07:29:03.373611Z","relpermalink":"/publication/2020-cvpr-irnet/","section":"publication","summary":"","tags":[],"title":"Forward and Backward Information Retention for Accurate Binary Neural Networks","type":"publication"},{"authors":["Yudong Wu","Yichao Wu","Ruihao Gong","Yuanhao Lv","Ken Chen","Ding Liang","Xiaolin Hu","Xianglong Liu","Junjie Yan"],"categories":[],"content":"","date":1590969600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648366067,"objectID":"4f56f2df3811eb5cfff12a63bac70e85","permalink":"https://example.com/publication/2020-cvpr-rcmloss/","publishdate":"2022-03-27T07:29:03.922862Z","relpermalink":"/publication/2020-cvpr-rcmloss/","section":"publication","summary":"","tags":[],"title":"Rotation Consistent Margin Loss for Efficient Low-bit Face Recognition","type":"publication"},{"authors":["Feng Zhu","Ruihao Gong","Fengwei Yu","Xianglong Liu","Yanfei Wang","Zhelong Li","Xiuqi Yang","Junjie Yan"],"categories":[],"content":"","date":1590969600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648366068,"objectID":"ad1126ec12d50f3ae21276375e7b9b69","permalink":"https://example.com/publication/2020-cvpr-int-8-training/","publishdate":"2022-03-27T07:29:04.472601Z","relpermalink":"/publication/2020-cvpr-int-8-training/","section":"publication","summary":"","tags":[],"title":"Towards Unified INT8 Training for Convolutional Neural Network","type":"publication"},{"authors":["Mingzhu Shen","Xianglong Liu","Ruihao Gong","Kai Han"],"categories":[],"content":"","date":1588291200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648366065,"objectID":"0aebb1b84ac5e9a160c6f974f10a1c5e","permalink":"https://example.com/publication/2020-icassp-bbg/","publishdate":"2022-03-27T07:29:02.282811Z","relpermalink":"/publication/2020-icassp-bbg/","section":"publication","summary":"","tags":[],"title":"Balanced Binary Neural Networks with Gated Residual","type":"publication"},{"authors":["Yuhang Li","Ruihao Gong","Fengwei Yu","Xin Dong","Xianglong Liu"],"categories":[],"content":"","date":1585699200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648366066,"objectID":"4dbd646e758b7ce6813e79376e788921","permalink":"https://example.com/publication/2020-iclrw-dms/","publishdate":"2022-03-27T07:29:02.826575Z","relpermalink":"/publication/2020-iclrw-dms/","section":"publication","summary":"","tags":[],"title":"DMS: Differentiable Dimension Search for Binary Neural Networks","type":"publication"},{"authors":["Haotong Qin","Ruihao Gong","Xianglong Liu","Xiao Bai","Jingkuan Song","Nicu Sebe"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648366068,"objectID":"212f185d09ce3c066ebedcc2e396d21a","permalink":"https://example.com/publication/2020-pr-bnnsurvey/","publishdate":"2022-03-27T07:29:05.018687Z","relpermalink":"/publication/2020-pr-bnnsurvey/","section":"publication","summary":"The binary neural network, largely saving the storage and computation, serves as a promising technique for deploying deep models on resource-limited devices. However, the binarization inevitably causes severe information loss, and even worse, its discontinuity brings difficulty to the optimization of the deep network. To address these issues, a variety of algorithms have been proposed, and achieved satisfying progress in recent years. In this paper, we present a comprehensive survey of these algorithms, mainly categorized into the native solutions directly conducting binarization, and the optimized ones using techniques like minimizing the quantization error, improving the network loss function, and reducing the gradient error. We also investigate other practical aspects of binary neural networks such as the hardware-friendly design and the training tricks. Then, we give the evaluation and discussions on different tasks, including image classification, object detection and semantic segmentation. Finally, the challenges that may be faced in future research are prospected.","tags":["Binary neural network","Deep learning","Model compression","Network quantization","Model acceleration"],"title":"Binary neural networks: A survey","type":"publication"},{"authors":["Yuhang Li","Wei Wang","Haoli Bai","Ruihao Gong","Xin Dong","Fengwei Yu"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648366062,"objectID":"32738930d483fa6f4e26a6a2115188b4","permalink":"https://example.com/publication/2020-arxiv-ebs/","publishdate":"2022-03-27T07:28:59.476187Z","relpermalink":"/publication/2020-arxiv-ebs/","section":"publication","summary":"","tags":[],"title":"Efficient Bitwidth Search for Practical Mixed Precision Neural Network","type":"publication"},{"authors":["Qingchang Han","Yongmin Hu","Fengwei Yu","Hailong Yang","Bing Liu","Peng Hu","Ruihao Gong","Yanfei Wang","Rui Wang","Zhongzhi Luan","Depei Qian"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648366064,"objectID":"5b58a06350e087633976687b4a9bdca9","permalink":"https://example.com/publication/2020-icpp-lowbit/","publishdate":"2022-03-27T07:29:00.583344Z","relpermalink":"/publication/2020-icpp-lowbit/","section":"publication","summary":"With the continuous demand for higher accuracy of deep neural networks, the model size has increased significantly. Quantization is one of the most widely used model compression methods, which can effectively reduce the model size without severe accuracy loss. Modern processors such as ARM CPU and NVIDIA GPU have already provided the support of low-bit arithmetic instructions. However, there lack efficient and practical optimizations for convolution computation towards extremely low-bit on ARM CPU (e.g., 2 ‚àº 8-bit) and NVIDIA GPU (e.g., 4-bit and 8-bit). This paper explores the performance optimization methods of extremely low-bit convolution on diverse architectures. On ARM CPU, we propose two instruction schemes for 2 ‚àº 3-bit and 4 ‚àº 8-bit convolution with corresponding register allocation methods. In addition, we re-design the GEMM computation with data padding and packing optimizations. We also implement winograd algorithm for convolution with some specific bit width (e.g., 4 ‚àº 6-bit) to achieve higher performance. On NVIDIA GPU, we propose a data partition mechanism and multi-level memory access optimizations, to better adapt the computation to GPU thread and memory hierarchy. We also propose quantization fusion to eliminate unnecessary data access. The experiment results demonstrate our implementations achieve better performance of extremely low-bit convolution compared to the state-of-the-art frameworks and libraries such as ncnn and cuDNN. To the best of our knowledge, this is the first work that provides efficient implementations of extremely low-bit convolutions covering 2 ‚àº 8-bit on ARM CPU and 4-bit/8-bit on NVIDIA GPU. ","tags":["NVIDIA GPU","Quantized Neural Network","Extremely Low-bit Convolution","Computation Optimization","ARM CPU"],"title":"Extremely Low-Bit Convolution Optimization for Quantized Neural Network on Modern Computer Architectures","type":"publication"},{"authors":["Ruihao Gong","Xianglong Liu","Shenghu Jiang","Tianxiang Li","Peng Hu","Jiazhen Lin","Fengwei Yu","Junjie Yan"],"categories":[],"content":"","date":1569888000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648366063,"objectID":"b2b8d8079ac76ff65a1d3a5926745606","permalink":"https://example.com/publication/2019-iccv-dsq/","publishdate":"2022-03-27T07:29:00.032371Z","relpermalink":"/publication/2019-iccv-dsq/","section":"publication","summary":"","tags":[],"title":"Differentiable Soft Quantization: Bridging Full-Precision and Low-Bit Neural Networks","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34;\rif porridge == \u0026#34;blueberry\u0026#34;:\rprint(\u0026#34;Eating...\u0026#34;)\r  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}}\r{{% fragment %}} **Two** {{% /fragment %}}\r{{% fragment %}} Three {{% /fragment %}}\r Press Space to play!\nOne \rTwo \rThree \r A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}}\r- Only the speaker can read these notes\r- Press `S` key to view\r{{% /speaker_note %}}\r Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}}\r{{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}}\r{{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}}\r  Custom CSS Example Let‚Äôs make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1,\r.reveal section h2,\r.reveal section h3 {\rcolor: navy;\r}\r  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://example.com/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"}]