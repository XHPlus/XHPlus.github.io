<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deep Learning | Ruihao Gong</title>
    <link>https://example.com/tag/deep-learning/</link>
      <atom:link href="https://example.com/tag/deep-learning/index.xml" rel="self" type="application/rss+xml" />
    <description>Deep Learning</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sun, 27 Aug 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://example.com/media/icon_hu0218ab8280f4fa11ac3ef903ebdf935e_6403_512x512_fill_lanczos_center_3.png</url>
      <title>Deep Learning</title>
      <link>https://example.com/tag/deep-learning/</link>
    </image>
    
    <item>
      <title>LPCV 2023 Winner Solution</title>
      <link>https://example.com/project/lpcv2023-fpga-track/</link>
      <pubDate>Sun, 27 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://example.com/project/lpcv2023-fpga-track/</guid>
      <description>&lt;p&gt;This project contains the complete implementation that wins the LPCV 2023 Challenge.&lt;/p&gt;
&lt;p&gt;The leaderboard can be seen at &lt;a href=&#34;https://lpcv.ai/scoreboard/Segmentation23&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LPCV2023 Leaderboard&lt;/a&gt; (ModelTC Team).&lt;/p&gt;
&lt;p&gt;Code:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ModelTC/LPCV_2023_solution&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/ModelTC/LPCV_2023_solution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ModelTC/UP_LPCV2023_Plugin&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/ModelTC/UP_LPCV2023_Plugin&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>LPCV 2021 Winner Solution of FPGA Track</title>
      <link>https://example.com/project/lpcv2021-fpga-track/</link>
      <pubDate>Fri, 27 Aug 2021 00:00:00 +0000</pubDate>
      <guid>https://example.com/project/lpcv2021-fpga-track/</guid>
      <description>&lt;p&gt;This project contains the complete implementation that wins the LPCV 2021 FPGA track, which can run an object detection model with an extremely high efficiency and accuracy.&lt;/p&gt;
&lt;p&gt;The leaderboard can be seen at &lt;a href=&#34;https://lpcv.ai/scoreboard/FPGA21&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LPCV2021 Leaderboard&lt;/a&gt; (Spring Team).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MQBench</title>
      <link>https://example.com/project/mqbench/</link>
      <pubDate>Tue, 27 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://example.com/project/mqbench/</guid>
      <description>&lt;p&gt;MQBench is an open-source model quantization toolkit based on PyTorch fx.&lt;/p&gt;
&lt;p&gt;The envision of MQBench is to provide:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SOTA Algorithms. With MQBench, the hardware vendors and researchers can benefit from the latest research progress in academia.&lt;/li&gt;
&lt;li&gt;Powerful Toolkits. With the toolkit, quantization node can be inserted to the original PyTorch module automatically with respect to the specific hardware. After training, the quantized model can be smoothly converted to the format that can inference on the real device.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The documentation can be seen at &lt;a href=&#34;https://mqbench.readthedocs.io/en/latest/?badge=latest&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt; and the website is at &lt;a href=&#34;http://mqbench.tech/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Link&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>RobustART</title>
      <link>https://example.com/project/robustart/</link>
      <pubDate>Sun, 27 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://example.com/project/robustart/</guid>
      <description>&lt;p&gt;RobustART is a comprehensive Robustness investigation benchmark on ImageNet regarding ARchitectural design (49 human-designed off-the-shelf architectures and neural architecture searched networks) and Training techniques (10+ general ones e.g., extra training data, etc) towards diverse noises (adversarial, natural, and system noises).&lt;/p&gt;
&lt;p&gt;The benchmark (including open-source toolkit, pre-trained model zoo, datasets, and analyses):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;presents an open-source platform for conducting comprehensive evaluation on diverse robustness types;&lt;/li&gt;
&lt;li&gt;provides a variety of pre-trained models with different training techniques to facilitate robustness evaluation;&lt;/li&gt;
&lt;li&gt;proposes a new view to better understand the mechanism towards designing robust DNN architectures, backed up by the analysis.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more details, please refer to the &lt;a href=&#34;http://robust.art/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;website&lt;/a&gt;. We will continuously contribute to building this ecosystem for the community.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Binary neural networks: A survey</title>
      <link>https://example.com/publication/2020-pr-bnnsurvey/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://example.com/publication/2020-pr-bnnsurvey/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
