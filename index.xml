<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ruihao Gong</title>
    <link>https://example.com/</link>
      <atom:link href="https://example.com/index.xml" rel="self" type="application/rss+xml" />
    <description>Ruihao Gong</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sat, 01 Jan 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://example.com/media/icon_hu0218ab8280f4fa11ac3ef903ebdf935e_6403_512x512_fill_lanczos_center_3.png</url>
      <title>Ruihao Gong</title>
      <link>https://example.com/</link>
    </image>
    
    <item>
      <title>QDrop: Randomly Dropping Quantization for Extremely Low-bit Post-Training Quantization</title>
      <link>https://example.com/publication/2022-iclr-qdrop/</link>
      <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://example.com/publication/2022-iclr-qdrop/</guid>
      <description></description>
    </item>
    
    <item>
      <title>MixMix: All You Need for Data-Free Compression Are Feature and Data Mixing</title>
      <link>https://example.com/publication/2021-iccv-mixmix/</link>
      <pubDate>Fri, 01 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://example.com/publication/2021-iccv-mixmix/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Once Quantization-Aware Training: High Performance Extremely Low-Bit Architecture Search</title>
      <link>https://example.com/publication/2021-iccv-oqa/</link>
      <pubDate>Fri, 01 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://example.com/publication/2021-iccv-oqa/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Research on Post-training Quantization - From classic to original</title>
      <link>https://example.com/talk/research-on-post-training-quantization-from-classic-to-original/</link>
      <pubDate>Fri, 27 Aug 2021 19:00:00 +0000</pubDate>
      <guid>https://example.com/talk/research-on-post-training-quantization-from-classic-to-original/</guid>
      <description>&lt;p&gt;A summary can be seen at &lt;a href=&#34;https://mp.weixin.qq.com/s/cuzBmjw_4cdmLlgVHHS03Q&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Link&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>LPCV2021 Winner Solution of FPGA Track</title>
      <link>https://example.com/project/lpcv2021-fpga-track/</link>
      <pubDate>Fri, 27 Aug 2021 00:00:00 +0000</pubDate>
      <guid>https://example.com/project/lpcv2021-fpga-track/</guid>
      <description>&lt;p&gt;This project contains the complete implementation that wins the LPCV 2021 FPGA track, which can run an object detection model with an extremely high efficiency and accuracy.&lt;/p&gt;
&lt;p&gt;The leaderboard can be seen at &lt;a href=&#34;https://lpcv.ai/scoreboard/FPGA21&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LPCV2021 Leaderboard&lt;/a&gt; (Spring Team).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Block Sparsity on TVM -- 50% spasity = 1.6 speed up &#43; &lt; 1% accuracy loss</title>
      <link>https://example.com/post/2021-tvm-sparsity/</link>
      <pubDate>Thu, 26 Aug 2021 00:00:00 +0000</pubDate>
      <guid>https://example.com/post/2021-tvm-sparsity/</guid>
      <description>&lt;p&gt;For details, please refer to &lt;a href=&#34;https://zhuanlan.zhihu.com/p/403869592&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Link&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Quantization frameworks</title>
      <link>https://example.com/post/2021-quant-tool/</link>
      <pubDate>Tue, 17 Aug 2021 00:00:00 +0000</pubDate>
      <guid>https://example.com/post/2021-quant-tool/</guid>
      <description>&lt;p&gt;For details, please refer to &lt;a href=&#34;https://zhuanlan.zhihu.com/p/355598250&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Link&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MQBench</title>
      <link>https://example.com/project/mqbench/</link>
      <pubDate>Tue, 27 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://example.com/project/mqbench/</guid>
      <description>&lt;p&gt;MQBench is an open-source model quantization toolkit based on PyTorch fx.&lt;/p&gt;
&lt;p&gt;The envision of MQBench is to provide:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SOTA Algorithms. With MQBench, the hardware vendors and researchers can benefit from the latest research progress in academia.&lt;/li&gt;
&lt;li&gt;Powerful Toolkits. With the toolkit, quantization node can be inserted to the original PyTorch module automatically with respect to the specific hardware. After training, the quantized model can be smoothly converted to the format that can inference on the real device.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The documentation can be seen at &lt;a href=&#34;https://mqbench.readthedocs.io/en/latest/?badge=latest&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt; and the website is at &lt;a href=&#34;http://mqbench.tech/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Link&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MQBench: Towards Reproducible and Deployable Model Quantization Benchmark</title>
      <link>https://example.com/publication/2021-neuips-mqbench/</link>
      <pubDate>Thu, 01 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://example.com/publication/2021-neuips-mqbench/</guid>
      <description></description>
    </item>
    
    <item>
      <title>RobustART</title>
      <link>https://example.com/project/robustart/</link>
      <pubDate>Sun, 27 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://example.com/project/robustart/</guid>
      <description>&lt;p&gt;RobustART is a comprehensive Robustness investigation benchmark on ImageNet regarding ARchitectural design (49 human-designed off-the-shelf architectures and neural architecture searched networks) and Training techniques (10+ general ones e.g., extra training data, etc) towards diverse noises (adversarial, natural, and system noises).&lt;/p&gt;
&lt;p&gt;The benchmark (including open-source toolkit, pre-trained model zoo, datasets, and analyses):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;presents an open-source platform for conducting comprehensive evaluation on diverse robustness types;&lt;/li&gt;
&lt;li&gt;provides a variety of pre-trained models with different training techniques to facilitate robustness evaluation;&lt;/li&gt;
&lt;li&gt;proposes a new view to better understand the mechanism towards designing robust DNN architectures, backed up by the analysis.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more details, please refer to the &lt;a href=&#34;http://robust.art/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;website&lt;/a&gt;. We will continuously contribute to building this ecosystem for the community.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Diversifying Sample Generation for Accurate Data-Free Quantization</title>
      <link>https://example.com/publication/2021-cvpr-dsg/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://example.com/publication/2021-cvpr-dsg/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Neural Network Model Compression</title>
      <link>https://example.com/talk/neural-network-model-compression/</link>
      <pubDate>Thu, 06 May 2021 19:00:00 +0000</pubDate>
      <guid>https://example.com/talk/neural-network-model-compression/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Int8 ViT on TVM, 1.5 speed up compared with TensorRT</title>
      <link>https://example.com/post/2021-vit-tvm-quant/</link>
      <pubDate>Mon, 19 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://example.com/post/2021-vit-tvm-quant/</guid>
      <description>&lt;p&gt;For details, please refer to &lt;a href=&#34;https://mp.weixin.qq.com/s/BtxmGr2YUyY1zDdL4sCJ9w&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Link&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An Introduction to Block Reconstruction Quantization</title>
      <link>https://example.com/talk/an-introduction-to-block-reconstruction-quantization/</link>
      <pubDate>Wed, 14 Apr 2021 19:00:00 +0000</pubDate>
      <guid>https://example.com/talk/an-introduction-to-block-reconstruction-quantization/</guid>
      <description>&lt;p&gt;A summary can be seen at &lt;a href=&#34;https://mp.weixin.qq.com/s/KDez283UKmnY6Ry3K1d7-g&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Link&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Gap bettween the academia and industry, from the quantiztion perspective</title>
      <link>https://example.com/post/2021-quant-gap/</link>
      <pubDate>Mon, 08 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://example.com/post/2021-quant-gap/</guid>
      <description>&lt;p&gt;For details, please refer to &lt;a href=&#34;https://zhuanlan.zhihu.com/p/349820682&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Link&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>BRECQ: Pushing the Limit of Post-Training Quantization by Block Reconstruction</title>
      <link>https://example.com/publication/2021-iclr-brecq/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://example.com/publication/2021-iclr-brecq/</guid>
      <description></description>
    </item>
    
    <item>
      <title>RobustART: Benchmarking Robustness on Architecture Design and Training Techniques</title>
      <link>https://example.com/publication/2021-arxiv-robustart/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://example.com/publication/2021-arxiv-robustart/</guid>
      <description></description>
    </item>
    
    <item>
      <title>An Introduction to Quantization</title>
      <link>https://example.com/talk/an-introduction-to-quantization/</link>
      <pubDate>Tue, 09 Jun 2020 19:00:00 +0000</pubDate>
      <guid>https://example.com/talk/an-introduction-to-quantization/</guid>
      <description>&lt;p&gt;A summary can be seen at &lt;a href=&#34;https://mp.weixin.qq.com/s/yC2Jb4feobD1MttblHw_xg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Forward and Backward Information Retention for Accurate Binary Neural Networks</title>
      <link>https://example.com/publication/2020-cvpr-irnet/</link>
      <pubDate>Mon, 01 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://example.com/publication/2020-cvpr-irnet/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Rotation Consistent Margin Loss for Efficient Low-bit Face Recognition</title>
      <link>https://example.com/publication/2020-cvpr-rcmloss/</link>
      <pubDate>Mon, 01 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://example.com/publication/2020-cvpr-rcmloss/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Towards Unified INT8 Training for Convolutional Neural Network</title>
      <link>https://example.com/publication/2020-cvpr-int-8-training/</link>
      <pubDate>Mon, 01 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://example.com/publication/2020-cvpr-int-8-training/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Balanced Binary Neural Networks with Gated Residual</title>
      <link>https://example.com/publication/2020-icassp-bbg/</link>
      <pubDate>Fri, 01 May 2020 00:00:00 +0000</pubDate>
      <guid>https://example.com/publication/2020-icassp-bbg/</guid>
      <description></description>
    </item>
    
    <item>
      <title>DMS: Differentiable Dimension Search for Binary Neural Networks</title>
      <link>https://example.com/publication/2020-iclrw-dms/</link>
      <pubDate>Wed, 01 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://example.com/publication/2020-iclrw-dms/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Binary neural networks: A survey</title>
      <link>https://example.com/publication/2020-pr-bnnsurvey/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://example.com/publication/2020-pr-bnnsurvey/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Efficient Bitwidth Search for Practical Mixed Precision Neural Network</title>
      <link>https://example.com/publication/2020-arxiv-ebs/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://example.com/publication/2020-arxiv-ebs/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Extremely Low-Bit Convolution Optimization for Quantized Neural Network on Modern Computer Architectures</title>
      <link>https://example.com/publication/2020-icpp-lowbit/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://example.com/publication/2020-icpp-lowbit/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Differentiable Soft Quantization: Bridging Full-Precision and Low-Bit Neural Networks</title>
      <link>https://example.com/publication/2019-iccv-dsq/</link>
      <pubDate>Tue, 01 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://example.com/publication/2019-iccv-dsq/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>https://example.com/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://example.com/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-wowchemy&#34;&gt;Create slides in Markdown with Wowchemy&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wowchemy&lt;/a&gt; | &lt;a href=&#34;https://owchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
    print(&amp;quot;Eating...&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;fragment &#34; &gt;
One
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
&lt;strong&gt;Two&lt;/strong&gt;
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
Three
&lt;/span&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; slide background-image=&amp;quot;/media/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.reveal section h1,
.reveal section h2,
.reveal section h3 {
  color: navy;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wowchemy/wowchemy-hugo-modules/discussions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://example.com/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://example.com/admin/config.yml</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
